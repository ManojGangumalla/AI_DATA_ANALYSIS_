{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AI for Anomalies Detection in Data Quality\n",
    "**Description**: Implement an AI-based approach to detect anomalies in data quality.\n",
    "\n",
    "**Steps**:\n",
    "1. Use an Anomaly Detection Algorithm:\n",
    "    - Use sklearn's Isolation Forest for anomaly detection.\n",
    "\n",
    "**Example data:**\n",
    "\n",
    "data = np.array([[25, 50000], [30, 60000], [35, 75000], [40, None], [45, 100000]])\n",
    "\n",
    "2. Integrate with Great Expectations:\n",
    "    - Generate alerts if anomalies are detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Detected Anomalies:\n",
      "    age  income  anomaly\n",
      "3   40     NaN       -1\n"
     ]
    },
    {
     "ename": "DataContextError",
     "evalue": "Datasource is not a FluentDatasource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataContextError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m datasource_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_pandas_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datasource_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m context\u001b[38;5;241m.\u001b[39mlist_datasources():\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_datasource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatasource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPandasExecutionEngine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_connectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruntime_data_connector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRuntimeDataConnector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_identifiers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_identifier_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Step 7: Create a batch request from the DataFrame\u001b[39;00m\n\u001b[1;32m     41\u001b[0m batch_request \u001b[38;5;241m=\u001b[39m RuntimeBatchRequest(\n\u001b[1;32m     42\u001b[0m     datasource_name\u001b[38;5;241m=\u001b[39mdatasource_name,\n\u001b[1;32m     43\u001b[0m     data_connector_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime_data_connector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     batch_identifiers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_identifier_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_id\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     47\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/great_expectations/data_context/data_context/abstract_data_context.py:718\u001b[0m, in \u001b[0;36mAbstractDataContext.add_datasource\u001b[0;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;129m@new_argument\u001b[39m(\n\u001b[1;32m    692\u001b[0m     argument_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    693\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.15.49\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FluentDatasource \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add a new Datasource to the data context, with configuration provided as kwargs.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    --Documentation--\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m        Datasource instance added.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_datasource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitialize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/great_expectations/data_context/data_context/abstract_data_context.py:758\u001b[0m, in \u001b[0;36mAbstractDataContext._add_datasource\u001b[0;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_fluent_datasource(\n\u001b[1;32m    755\u001b[0m         datasource\u001b[38;5;241m=\u001b[39mdatasource,\n\u001b[1;32m    756\u001b[0m     )\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataContextError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource is not a FluentDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# noqa: TRY003 # FIXME CoP\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datasource\n",
      "\u001b[0;31mDataContextError\u001b[0m: Datasource is not a FluentDatasource"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import great_expectations as ge\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "\n",
    "# Step 1: Sample data\n",
    "data = [[25, 50000], [30, 60000], [35, 75000], [40, None], [45, 100000]]\n",
    "df = pd.DataFrame(data, columns=[\"age\", \"income\"])\n",
    "\n",
    "# Step 2: Prepare data for Isolation Forest\n",
    "df_filled = df.fillna(-999)  # Handle missing income\n",
    "\n",
    "# Step 3: Apply Isolation Forest\n",
    "iso = IsolationForest(contamination=0.2, random_state=42)\n",
    "df['anomaly'] = iso.fit_predict(df_filled)\n",
    "\n",
    "# Step 4: Print anomalies\n",
    "anomalies = df[df[\"anomaly\"] == -1]\n",
    "print(\"🔎 Detected Anomalies:\\n\", anomalies)\n",
    "\n",
    "# Step 5: Load or create a Great Expectations context\n",
    "context = ge.get_context()\n",
    "\n",
    "# Step 6: Add a temporary in-memory datasource\n",
    "datasource_name = \"my_pandas_datasource\"\n",
    "if datasource_name not in context.list_datasources():\n",
    "    context.add_datasource(\n",
    "        name=datasource_name,\n",
    "        class_name=\"Datasource\",\n",
    "        execution_engine={\"class_name\": \"PandasExecutionEngine\"},\n",
    "        data_connectors={\n",
    "            \"runtime_data_connector\": {\n",
    "                \"class_name\": \"RuntimeDataConnector\",\n",
    "                \"batch_identifiers\": [\"default_identifier_name\"]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Step 7: Create a batch request from the DataFrame\n",
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=datasource_name,\n",
    "    data_connector_name=\"runtime_data_connector\",\n",
    "    data_asset_name=\"anomaly_data\",\n",
    "    runtime_parameters={\"batch_data\": df},\n",
    "    batch_identifiers={\"default_identifier_name\": \"default_id\"},\n",
    ")\n",
    "\n",
    "# Step 8: Create expectation suite\n",
    "suite_name = \"anomaly_suite\"\n",
    "if suite_name not in context.list_expectation_suites():\n",
    "    context.create_expectation_suite(suite_name)\n",
    "\n",
    "# Step 9: Get validator\n",
    "validator = context.get_validator(batch_request=batch_request, expectation_suite_name=suite_name)\n",
    "\n",
    "# Step 10: Optional: Add some sanity checks\n",
    "validator.expect_column_values_to_not_be_null(\"income\")\n",
    "\n",
    "# Step 11: Generate alert\n",
    "if (df[\"anomaly\"] == -1).any():\n",
    "    print(f\"\\n⚠️ ALERT: {sum(df['anomaly'] == -1)} anomaly/anomalies detected!\")\n",
    "else:\n",
    "    print(\"\\n✅ No anomalies detected.\")\n",
    "\n",
    "# Step 12: Run validation\n",
    "results = validator.validate()\n",
    "print(\"\\nValidation Results:\")\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
