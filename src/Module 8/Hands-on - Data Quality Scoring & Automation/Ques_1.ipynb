{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Metrics:\n",
      "---------------------\n",
      "Completeness per column (%):\n",
      "Name      83.333333\n",
      "Email    100.000000\n",
      "Age       83.333333\n",
      "dtype: float64\n",
      "\n",
      "Email Validity (% with '@'): 83.33%\n",
      "Unique Emails Count: 6\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Sample CSV data as a multi-line string\n",
    "csv_data = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob.example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,david@example,22\n",
    ",Eve@example.com,28\n",
    "Frank,frank@example.com,33\n",
    "\"\"\"\n",
    "\n",
    "# Use StringIO to simulate reading from a file\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "\n",
    "# 1. Completeness: Percentage of non-null values per column\n",
    "completeness = df.notnull().mean() * 100\n",
    "\n",
    "# 2. Validity: % of email fields containing '@'\n",
    "valid_emails = df['Email'].str.contains('@', na=False).mean() * 100\n",
    "\n",
    "# 3. Uniqueness: Count distinct entries in the Email column\n",
    "unique_emails = df['Email'].nunique()\n",
    "\n",
    "# Print results\n",
    "print(\"Data Quality Metrics:\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Completeness per column (%):\\n{completeness}\\n\")\n",
    "print(f\"Email Validity (% with '@'): {valid_emails:.2f}%\")\n",
    "print(f\"Unique Emails Count: {unique_emails}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Metrics:\n",
      "---------------------\n",
      "Completeness per column (%):\n",
      "Name      83.333333\n",
      "Email    100.000000\n",
      "Age       83.333333\n",
      "dtype: float64\n",
      "\n",
      "Average Completeness (%): 88.89%\n",
      "Email Validity (% with '@'): 83.33%\n",
      "Email Uniqueness (% unique): 100.00%\n",
      "---------------------\n",
      "Overall Data Quality Score: 90.74%\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Sample CSV data\n",
    "csv_data = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob.example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,david@example,22\n",
    ",Eve@example.com,28\n",
    "Frank,frank@example.com,33\n",
    "\"\"\"\n",
    "\n",
    "# Load data into DataFrame\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "\n",
    "# 1. Completeness: Percentage of non-null values per column\n",
    "completeness = df.notnull().mean() * 100\n",
    "\n",
    "# 2. Validity: % of email fields containing '@'\n",
    "valid_emails = df['Email'].str.contains('@', na=False).mean() * 100\n",
    "\n",
    "# 3. Uniqueness: Percentage of unique emails relative to total emails\n",
    "unique_emails_count = df['Email'].nunique()\n",
    "total_emails_count = df['Email'].notnull().sum()\n",
    "uniqueness = (unique_emails_count / total_emails_count) * 100 if total_emails_count > 0 else 0\n",
    "\n",
    "# Calculate Data Quality Score: average of completeness, validity, and uniqueness\n",
    "# We take average completeness across columns\n",
    "avg_completeness = completeness.mean()\n",
    "data_quality_score = (avg_completeness + valid_emails + uniqueness) / 3\n",
    "\n",
    "# Print results\n",
    "print(\"Data Quality Metrics:\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Completeness per column (%):\\n{completeness}\\n\")\n",
    "print(f\"Average Completeness (%): {avg_completeness:.2f}%\")\n",
    "print(f\"Email Validity (% with '@'): {valid_emails:.2f}%\")\n",
    "print(f\"Email Uniqueness (% unique): {uniqueness:.2f}%\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Overall Data Quality Score: {data_quality_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'read_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(csv_content)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Step 2: Load CSV as Great Expectations dataset\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m df_ge \u001b[38;5;241m=\u001b[39m \u001b[43mge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Step 3: Create an Expectation Suite and add completeness expectations\u001b[39;00m\n\u001b[1;32m     22\u001b[0m expectation_suite_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleteness_suite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'read_csv'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "# Step 1: Create sample CSV file\n",
    "csv_content = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob.example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,david@example,22\n",
    ",Eve@example.com,28\n",
    "Frank,frank@example.com,33\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sample_data.csv\", \"w\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "# Step 2: Load CSV as Great Expectations dataset\n",
    "df_ge = ge.read_csv(\"sample_data.csv\")\n",
    "\n",
    "# Step 3: Create an Expectation Suite and add completeness expectations\n",
    "expectation_suite_name = \"completeness_suite\"\n",
    "\n",
    "# Set default result format to SUMMARY for clean output\n",
    "df_ge.set_default_expectation_argument(\"result_format\", \"SUMMARY\")\n",
    "\n",
    "# Add expectations: values should not be null for all columns\n",
    "for col in df_ge.columns:\n",
    "    df_ge.expect_column_values_to_not_be_null(col)\n",
    "\n",
    "# Step 4: Save the expectation suite (optional)\n",
    "df_ge.save_expectation_suite(expectation_suite_name + \".json\")\n",
    "\n",
    "# Step 5: Validate the dataset against the expectations\n",
    "results = df_ge.validate()\n",
    "\n",
    "# Step 6: Print validation results\n",
    "print(\"Validation Results Summary:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'read_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(csv_content)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Step 2: Load CSV as GE dataset\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m df_ge \u001b[38;5;241m=\u001b[39m \u001b[43mge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Step 3: Create an Expectation Suite and add completeness expectations\u001b[39;00m\n\u001b[1;32m     23\u001b[0m expectation_suite_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleteness_suite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'read_csv'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context.types.resource_identifiers import ValidationResultIdentifier\n",
    "\n",
    "# Step 1: Create sample CSV file (if not already created)\n",
    "csv_content = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob.example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,david@example,22\n",
    ",Eve@example.com,28\n",
    "Frank,frank@example.com,33\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sample_data.csv\", \"w\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "# Step 2: Load CSV as GE dataset\n",
    "df_ge = ge.read_csv(\"sample_data.csv\")\n",
    "\n",
    "# Step 3: Create an Expectation Suite and add completeness expectations\n",
    "expectation_suite_name = \"completeness_suite\"\n",
    "df_ge.set_default_expectation_argument(\"result_format\", \"SUMMARY\")\n",
    "\n",
    "for col in df_ge.columns:\n",
    "    df_ge.expect_column_values_to_not_be_null(col)\n",
    "\n",
    "# Save the expectation suite (optional)\n",
    "df_ge.save_expectation_suite(expectation_suite_name + \".json\")\n",
    "\n",
    "# Step 4: Run validation\n",
    "results = df_ge.validate()\n",
    "\n",
    "print(\"Validation Results Summary:\")\n",
    "print(results)\n",
    "\n",
    "# Step 5: Generate HTML report\n",
    "# For this we use a DataContext to create a validation result and render an HTML site\n",
    "\n",
    "from great_expectations.data_context import DataContext\n",
    "import json\n",
    "\n",
    "# Initialize a DataContext in a temp directory\n",
    "context = DataContext()\n",
    "\n",
    "# Save the expectation suite to the DataContext's default location\n",
    "context.save_expectation_suite(df_ge.get_expectation_suite(), expectation_suite_name)\n",
    "\n",
    "# Run validation through DataContext to get a ValidationResultIdentifier\n",
    "batch_kwargs = {\"path\": \"sample_data.csv\", \"datasource\": \"default_datasource\"}\n",
    "batch = context.get_batch(batch_kwargs, expectation_suite_name)\n",
    "validation_result = context.run_validation_operator(\n",
    "    \"action_list_operator\", assets_to_validate=[batch]\n",
    ")\n",
    "\n",
    "# Get the validation result identifier\n",
    "validation_result_identifier = validation_result.list_validation_result_identifiers()[0]\n",
    "\n",
    "# Build HTML report for the validation result\n",
    "context.build_data_docs()\n",
    "\n",
    "# Get the URL of the generated HTML validation report\n",
    "site_urls = context.get_docs_sites_urls()\n",
    "print(\"\\nValidation HTML report available at:\")\n",
    "print(site_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'read_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(csv_content)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Load CSV as Great Expectations dataframe\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m df_ge \u001b[38;5;241m=\u001b[39m \u001b[43mge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Create Expectation Suite for completeness\u001b[39;00m\n\u001b[1;32m     23\u001b[0m expectation_suite_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleteness_suite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'read_csv'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "# Sample CSV content\n",
    "csv_content = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob.example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,david@example,22\n",
    ",Eve@example.com,28\n",
    "Frank,frank@example.com,33\n",
    "\"\"\"\n",
    "\n",
    "# Write CSV to file\n",
    "with open(\"sample_data.csv\", \"w\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "# Load CSV as Great Expectations dataframe\n",
    "df_ge = ge.read_csv(\"sample_data.csv\")\n",
    "\n",
    "# Create Expectation Suite for completeness\n",
    "expectation_suite_name = \"completeness_suite\"\n",
    "df_ge.set_default_expectation_argument(\"result_format\", \"SUMMARY\")\n",
    "\n",
    "for col in df_ge.columns:\n",
    "    df_ge.expect_column_values_to_not_be_null(col)\n",
    "\n",
    "# Validate completeness expectations\n",
    "validation_results = df_ge.validate()\n",
    "\n",
    "# Extract completeness results from validation\n",
    "completeness_scores = []\n",
    "for result in validation_results[\"results\"]:\n",
    "    if result[\"expectation_config\"][\"expectation_type\"] == \"expect_column_values_to_not_be_null\":\n",
    "        completeness_scores.append(result[\"result\"][\"element_count\"] - result[\"result\"][\"missing_count\"])\n",
    "\n",
    "total_rows = validation_results[\"results\"][0][\"result\"][\"element_count\"] if validation_results[\"results\"] else len(df_ge)\n",
    "\n",
    "avg_completeness_pct = (sum(completeness_scores) / (total_rows * len(df_ge.columns))) * 100 if total_rows > 0 else 0\n",
    "\n",
    "# Additional metrics calculated manually on original pandas dataframe\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "\n",
    "# Validity: % of email fields containing '@'\n",
    "valid_emails_pct = df['Email'].str.contains('@', na=False).mean() * 100\n",
    "\n",
    "# Uniqueness: % of unique emails relative to total non-null emails\n",
    "unique_email_count = df['Email'].nunique()\n",
    "total_non_null_emails = df['Email'].notnull().sum()\n",
    "uniqueness_pct = (unique_email_count / total_non_null_emails) * 100 if total_non_null_emails > 0 else 0\n",
    "\n",
    "# Calculate overall Data Quality Score (average of the three metrics)\n",
    "data_quality_score = (avg_completeness_pct + valid_emails_pct + uniqueness_pct) / 3\n",
    "\n",
    "# Output the scores\n",
    "print(f\"Completeness (Average %): {avg_completeness_pct:.2f}%\")\n",
    "print(f\"Email Validity (% containing '@'): {valid_emails_pct:.2f}%\")\n",
    "print(f\"Email Uniqueness (% unique emails): {uniqueness_pct:.2f}%\")\n",
    "print(f\"\\nOverall Data Quality Score: {data_quality_score:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'from_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Step 3: Load data and wrap with Great Expectations\u001b[39;00m\n\u001b[1;32m     29\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m df_ge \u001b[38;5;241m=\u001b[39m \u001b[43mge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m(df)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Step 4: Set completeness expectations for all columns\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_ge\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'from_pandas'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "# Step 1: Create sample CSV file\n",
    "csv_content = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob.example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,david@example,22\n",
    ",Eve@example.com,28\n",
    "Frank,frank@example.com,33\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sample_data.csv\", \"w\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "# Step 2: Define automated cleaning logic\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Fill missing Age with median\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    # Keep only emails containing '@'\n",
    "    df = df[df['Email'].str.contains('@', na=False)]\n",
    "    # Fill missing Names with 'Unknown'\n",
    "    df['Name'] = df['Name'].fillna('Unknown')\n",
    "    return df\n",
    "\n",
    "# Step 3: Load data and wrap with Great Expectations\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "df_ge = ge.from_pandas(df)\n",
    "\n",
    "# Step 4: Set completeness expectations for all columns\n",
    "for col in df_ge.columns:\n",
    "    df_ge.expect_column_values_to_not_be_null(col)\n",
    "\n",
    "# Step 5: Validate data completeness\n",
    "results = df_ge.validate()\n",
    "\n",
    "# Step 6: Calculate completeness % from validation results\n",
    "total_rows = len(df)\n",
    "completeness_counts = []\n",
    "for res in results[\"results\"]:\n",
    "    if res[\"expectation_config\"][\"expectation_type\"] == \"expect_column_values_to_not_be_null\":\n",
    "        missing = res[\"result\"][\"missing_count\"]\n",
    "        completeness_counts.append(total_rows - missing)\n",
    "\n",
    "avg_completeness_pct = (sum(completeness_counts) / (total_rows * len(df.columns))) * 100\n",
    "\n",
    "# Step 7: Calculate email validity (% emails containing '@')\n",
    "validity_pct = df['Email'].str.contains('@', na=False).mean() * 100\n",
    "\n",
    "# Step 8: Calculate uniqueness (% unique emails)\n",
    "unique_email_count = df['Email'].nunique()\n",
    "non_null_email_count = df['Email'].notnull().sum()\n",
    "uniqueness_pct = (unique_email_count / non_null_email_count) * 100 if non_null_email_count > 0 else 0\n",
    "\n",
    "# Step 9: Calculate overall Data Quality Score\n",
    "data_quality_score = (avg_completeness_pct + validity_pct + uniqueness_pct) / 3\n",
    "\n",
    "print(f\"Completeness: {avg_completeness_pct:.2f}%\")\n",
    "print(f\"Email Validity: {validity_pct:.2f}%\")\n",
    "print(f\"Email Uniqueness: {uniqueness_pct:.2f}%\")\n",
    "print(f\"Overall Data Quality Score: {data_quality_score:.2f}%\")\n",
    "\n",
    "# Step 10: Automate cleaning if score below threshold\n",
    "threshold = 80\n",
    "if data_quality_score < threshold:\n",
    "    print(f\"Data Quality Score below {threshold}%. Running cleaning script...\")\n",
    "    df_cleaned = clean_data(df)\n",
    "    df_cleaned.to_csv(\"cleaned_sample_data.csv\", index=False)\n",
    "    print(\"Cleaned data saved to 'cleaned_sample_data.csv'.\")\n",
    "else:\n",
    "    print(f\"Data Quality Score meets threshold. No cleaning needed.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
