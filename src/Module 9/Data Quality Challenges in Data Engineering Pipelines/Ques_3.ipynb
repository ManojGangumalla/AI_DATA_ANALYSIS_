{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Management for Data Quality\n",
    "**Description**: Store and use metadata to manage data quality in a pipeline.\n",
    "\n",
    "**Steps**:\n",
    "1. Load metadata\n",
    "2. Load data\n",
    "3. Use metadata to validate data quality\n",
    "4. Show valid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error] Column 'age' has null values but is not nullable.\n",
      "[Error] Column 'age' has 2 values not castable to int.\n",
      "[Error] Column 'age' has values outside min_value 0.0.\n",
      "[Error] Column 'age' has values outside max_value 120.0.\n",
      "[Error] Column 'name' has null values but is not nullable.\n",
      "[Error] Column 'balance' has values outside min_value 0.0.\n",
      "Validation complete: 2 valid rows, 5 invalid rows removed.\n",
      "\n",
      "Valid data rows:\n",
      "   id age   name  balance\n",
      "0   1  25  Alice   1000.5\n",
      "4   5  29    Eve   1200.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_metadata(metadata_path):\n",
    "    try:\n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        # Basic sanity check\n",
    "        required_cols = {'column_name', 'data_type', 'nullable'}\n",
    "        if not required_cols.issubset(set(metadata.columns)):\n",
    "            raise ValueError(f\"Metadata missing required columns: {required_cols}\")\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to load metadata: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_data(data_path):\n",
    "    try:\n",
    "        data = pd.read_csv(data_path)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to load data: {e}\")\n",
    "        return None\n",
    "\n",
    "def safe_cast(value, to_type):\n",
    "    \"\"\"Try to cast value to the given type safely.\"\"\"\n",
    "    try:\n",
    "        if to_type == 'int':\n",
    "            # Convert float strings to int if possible\n",
    "            if isinstance(value, float) and value.is_integer():\n",
    "                return int(value)\n",
    "            return int(value)\n",
    "        elif to_type == 'float':\n",
    "            return float(value)\n",
    "        elif to_type == 'str':\n",
    "            return str(value)\n",
    "        else:\n",
    "            return value  # unknown types just return original\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def validate_data_quality(data, metadata):\n",
    "    valid_rows_mask = pd.Series([True] * len(data))\n",
    "\n",
    "    for _, row in metadata.iterrows():\n",
    "        col = row['column_name']\n",
    "        expected_type = row['data_type'].lower()\n",
    "        nullable = str(row['nullable']).lower() == 'true'\n",
    "\n",
    "        if col not in data.columns:\n",
    "            print(f\"[Warning] Column '{col}' missing in data.\")\n",
    "            valid_rows_mask &= False\n",
    "            continue\n",
    "\n",
    "        col_values = data[col]\n",
    "\n",
    "        # Nullability check\n",
    "        if not nullable:\n",
    "            non_null_mask = col_values.notnull()\n",
    "            valid_rows_mask &= non_null_mask\n",
    "            if not non_null_mask.all():\n",
    "                print(f\"[Error] Column '{col}' has null values but is not nullable.\")\n",
    "\n",
    "        # Type check with safe casting\n",
    "        casted_values = col_values.apply(lambda x: safe_cast(x, expected_type))\n",
    "        type_valid_mask = casted_values.notnull()\n",
    "        valid_rows_mask &= type_valid_mask\n",
    "        if not type_valid_mask.all():\n",
    "            invalid_count = (~type_valid_mask).sum()\n",
    "            print(f\"[Error] Column '{col}' has {invalid_count} values not castable to {expected_type}.\")\n",
    "\n",
    "        # Range checks if applicable\n",
    "        for bound in ['min_value', 'max_value']:\n",
    "            if bound in row and pd.notna(row[bound]):\n",
    "                try:\n",
    "                    bound_val = float(row[bound])\n",
    "                    if bound == 'min_value':\n",
    "                        range_mask = casted_values >= bound_val\n",
    "                    else:\n",
    "                        range_mask = casted_values <= bound_val\n",
    "                    valid_rows_mask &= range_mask.fillna(False)\n",
    "                    if not range_mask.all():\n",
    "                        print(f\"[Error] Column '{col}' has values outside {bound} {bound_val}.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Could not apply {bound} check for column '{col}': {e}\")\n",
    "\n",
    "    valid_data = data[valid_rows_mask]\n",
    "    invalid_count = len(data) - len(valid_data)\n",
    "    print(f\"Validation complete: {len(valid_data)} valid rows, {invalid_count} invalid rows removed.\")\n",
    "    return valid_data\n",
    "\n",
    "\n",
    "# Minimal test function (expand with more cases as needed)\n",
    "def test_validate_data_quality():\n",
    "    from io import StringIO\n",
    "\n",
    "    metadata_csv = \"\"\"column_name,data_type,nullable,min_value,max_value\n",
    "id,int,False,,\n",
    "age,int,False,0,120\n",
    "name,str,False,,\n",
    "balance,float,False,0,\n",
    "\"\"\"\n",
    "\n",
    "    data_csv = \"\"\"id,age,name,balance\n",
    "1,25,Alice,1000.5\n",
    "2,130,Bob,2000.0\n",
    "3,,Charlie,1500.0\n",
    "4,35,,500.0\n",
    "5,29,Eve,1200.0\n",
    "6,28,Frank,-50.0\n",
    "7,abc,Gary,300.0\n",
    "\"\"\"\n",
    "\n",
    "    metadata = pd.read_csv(StringIO(metadata_csv))\n",
    "    data = pd.read_csv(StringIO(data_csv))\n",
    "\n",
    "    valid_data = validate_data_quality(data, metadata)\n",
    "    print(\"\\nValid data rows:\")\n",
    "    print(valid_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    # metadata = load_metadata(\"metadata.csv\")\n",
    "    # data = load_data(\"data.csv\")\n",
    "    # if metadata is not None and data is not None:\n",
    "    #     valid_data = validate_data_quality(data, metadata)\n",
    "    test_validate_data_quality()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
