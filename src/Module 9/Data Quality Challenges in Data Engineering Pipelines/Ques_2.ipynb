{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Handling Schema Mismatches using Spark\n",
    "**Description**: Use Apache Spark to address schema mismatches by transforming data to match\n",
    "the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Create Spark session\n",
    "2. Load dataframe\n",
    "3. Define the expected schema\n",
    "4. Handle schema mismatches\n",
    "5. Show corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, BooleanType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def create_spark_session(app_name=\"SchemaMismatchHandling\"):\n",
    "    return SparkSession.builder.appName(app_name).getOrCreate()\n",
    "\n",
    "def load_data_with_checks(spark, file_path):\n",
    "    import os\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    try:\n",
    "        df = spark.read.option(\"header\", True).csv(file_path)\n",
    "        if df.rdd.isEmpty():\n",
    "            raise ValueError(\"Dataframe is empty.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading data: {e}\")\n",
    "\n",
    "def cast_and_validate_schema(df, expected_schema):\n",
    "    for field in expected_schema.fields:\n",
    "        col_name = field.name\n",
    "        col_type = field.dataType\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, col(col_name).cast(col_type))\n",
    "        else:\n",
    "            df = df.withColumn(col_name, col(col_name))  # could add null column if missing\n",
    "    df = df.select([field.name for field in expected_schema.fields])\n",
    "    \n",
    "    # Post-casting validation\n",
    "    for field in expected_schema.fields:\n",
    "        dtype = dict(df.dtypes)[field.name]\n",
    "        expected_type_name = field.dataType.simpleString()\n",
    "        if dtype != expected_type_name:\n",
    "            print(f\"Warning: Column '{field.name}' dtype '{dtype}' does not match expected '{expected_type_name}'\")\n",
    "    return df\n",
    "\n",
    "def main_spark_task(file_path):\n",
    "    spark = create_spark_session()\n",
    "    try:\n",
    "        df = load_data_with_checks(spark, file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data: {e}\")\n",
    "        spark.stop()\n",
    "        return\n",
    "    \n",
    "    expected_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"age\", IntegerType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"is_active\", BooleanType(), True),\n",
    "        StructField(\"balance\", FloatType(), True)\n",
    "    ])\n",
    "    \n",
    "    corrected_df = cast_and_validate_schema(df, expected_schema)\n",
    "    corrected_df.show()\n",
    "    \n",
    "    spark.stop()\n",
    "\n",
    "# Uncomment to test (replace 'your_data.csv' with your path)\n",
    "# main_spark_task('your_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Detect and Correct Incomplete Data in ETL\n",
    "**Description**: Use Python and Pandas to detect incomplete data in an ETL process and fill\n",
    "missing values with estimates.\n",
    "\n",
    "**Steps**:\n",
    "1. Detect incomplete data\n",
    "2. Fill missing values\n",
    "3. Report changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_and_correct_incomplete_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df.empty:\n",
    "            print(\"CSV file is empty.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(\"Initial missing values per column:\")\n",
    "    missing_before = df.isnull().sum()\n",
    "    print(missing_before[missing_before > 0])\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                mean_val = df[col].mean()\n",
    "                df[col].fillna(mean_val, inplace=True)\n",
    "                print(f\"Filled missing numeric '{col}' with mean: {mean_val}\")\n",
    "            else:\n",
    "                mode_series = df[col].mode()\n",
    "                if not mode_series.empty:\n",
    "                    mode_val = mode_series[0]\n",
    "                    df[col].fillna(mode_val, inplace=True)\n",
    "                    print(f\"Filled missing categorical '{col}' with mode: {mode_val}\")\n",
    "                else:\n",
    "                    print(f\"Cannot fill '{col}': mode not found (empty column).\")\n",
    "    \n",
    "    missing_after = df.isnull().sum()\n",
    "    print(\"\\nMissing values after filling:\")\n",
    "    print(missing_after[missing_after > 0] if missing_after.sum() > 0 else \"No missing values remaining.\")\n",
    "    \n",
    "    corrected_file_path = \"corrected_\" + file_path\n",
    "    df.to_csv(corrected_file_path, index=False)\n",
    "    print(f\"\\nCorrected data saved to '{corrected_file_path}'.\")\n",
    "\n",
    "# Uncomment to test (replace 'your_data.csv' with your path)\n",
    "# detect_and_correct_incomplete_data('your_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
