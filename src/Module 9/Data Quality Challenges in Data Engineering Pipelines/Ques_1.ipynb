{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Detecting Missing Values during Data Ingestion\n",
    "**Description**: You have a CSV file with missing values in some columns. Write a Python script to detect and report missing values during the ingestion process.\n",
    "\n",
    "**Steps**:\n",
    "1. Load data\n",
    "2. Check for missing values\n",
    "3. Report missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in dataset: 3\n",
      "Missing values per column:\n",
      "name     1\n",
      "age      1\n",
      "email    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def detect_missing_values(file_path):\n",
    "    # Step 1: Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Step 2: Check for missing values\n",
    "    missing_counts = df.isnull().sum()\n",
    "    \n",
    "    # Step 3: Report missing values\n",
    "    total_missing = missing_counts.sum()\n",
    "    if total_missing == 0:\n",
    "        print(\"No missing values detected in the dataset.\")\n",
    "    else:\n",
    "        print(f\"Total missing values in dataset: {total_missing}\")\n",
    "        print(\"Missing values per column:\")\n",
    "        print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Example usage\n",
    "csv_file = 'your_data.csv'  # Replace with your actual CSV file path\n",
    "detect_missing_values(csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Validate Data Types during Extraction\n",
    "**Description**: You have a JSON file that should have specific data types for each field. Write a script to validate if the data types match the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Define expected schema\n",
    "2. Validate data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type validation errors found:\n",
      "Record 1: Field 'age' expected int, got str\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import json\n",
    "\n",
    "def validate_data_types(json_file, schema):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # Assuming data is a list of records (dictionaries)\n",
    "    for i, record in enumerate(data):\n",
    "        for field, expected_type in schema.items():\n",
    "            if field not in record:\n",
    "                errors.append(f\"Record {i}: Missing field '{field}'\")\n",
    "            else:\n",
    "                if not isinstance(record[field], expected_type):\n",
    "                    # Special case: allow int where float expected\n",
    "                    if expected_type == float and isinstance(record[field], int):\n",
    "                        continue\n",
    "                    errors.append(f\"Record {i}: Field '{field}' expected {expected_type.__name__}, got {type(record[field]).__name__}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(\"Data type validation errors found:\")\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "    else:\n",
    "        print(\"All records match the expected schema.\")\n",
    "\n",
    "# Define expected schema: field -> Python type\n",
    "expected_schema = {\n",
    "    \"id\": int,\n",
    "    \"name\": str,\n",
    "    \"age\": int,\n",
    "    \"email\": str,\n",
    "    \"is_active\": bool,\n",
    "    \"balance\": float\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "json_file_path = 'data.json'  # Replace with your JSON file path\n",
    "validate_data_types(json_file_path, expected_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Remove Duplicate Records in Data\n",
    "**Description**: You have a dataset with duplicate entries. Write a Python script to find and remove duplicate records using Pandas.\n",
    "\n",
    "**Steps**:\n",
    "1. Find duplicate records\n",
    "2. Remove duplicates\n",
    "3. Report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records found: 0\n",
      "Number of records after removing duplicates: 5\n",
      "Cleaned data saved to cleaned_your_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def remove_duplicates(file_path):\n",
    "    # Step 1: Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Step 2: Find duplicate records\n",
    "    duplicates = df[df.duplicated()]\n",
    "    print(f\"Number of duplicate records found: {len(duplicates)}\")\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        print(\"Duplicate records:\")\n",
    "        print(duplicates)\n",
    "    \n",
    "    # Step 3: Remove duplicates\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    # Report results\n",
    "    print(f\"Number of records after removing duplicates: {len(df_cleaned)}\")\n",
    "    \n",
    "    # Optionally, save the cleaned data back to a new CSV file\n",
    "    cleaned_file_path = 'cleaned_' + file_path\n",
    "    df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"Cleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "csv_file = 'your_data.csv'  # Replace with your actual CSV file path\n",
    "remove_duplicates(csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
