{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Detecting Missing Values during Data Ingestion\n",
    "**Description**: You have a CSV file with missing values in some columns. Write a Python script to detect and report missing values during the ingestion process.\n",
    "\n",
    "**Steps**:\n",
    "1. Load data\n",
    "2. Check for missing values\n",
    "3. Report missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detect Missing Values ===\n",
      "Total missing values in dataset: 3\n",
      "Missing values per column:\n",
      "name     1\n",
      "age      1\n",
      "email    1\n",
      "dtype: int64\n",
      "\n",
      "=== Validate Data Types ===\n",
      "Data type validation errors found:\n",
      "Record 1: Field 'age' expected int, got str\n",
      "\n",
      "=== Remove Duplicates ===\n",
      "Number of duplicate records found: 0\n",
      "Number of records after removing duplicates: 5\n",
      "Cleaned data saved to cleaned_your_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# Helper Functions\n",
    "# ----------------------------\n",
    "\n",
    "def load_csv_with_checks(file_path):\n",
    "    \"\"\"\n",
    "    Safely load a CSV file with error handling for file existence and emptiness.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df.empty:\n",
    "            raise ValueError(\"CSV file is empty\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load CSV file: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_json_with_checks(file_path):\n",
    "    \"\"\"\n",
    "    Safely load a JSON file with error handling for file existence and emptiness.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        if not data:\n",
    "            raise ValueError(\"JSON file is empty\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load JSON file: {e}\")\n",
    "        raise\n",
    "\n",
    "def check_field_type(value, expected_type):\n",
    "    \"\"\"\n",
    "    Check if value matches expected type.\n",
    "    Allow int when float is expected.\n",
    "    \"\"\"\n",
    "    if isinstance(value, expected_type):\n",
    "        return True\n",
    "    if expected_type == float and isinstance(value, int):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def validate_schema_completeness(schema, sample_record):\n",
    "    \"\"\"\n",
    "    Check if all fields in sample_record exist in schema.\n",
    "    \"\"\"\n",
    "    missing_fields = set(sample_record.keys()) - set(schema.keys())\n",
    "    if missing_fields:\n",
    "        print(f\"Warning: Schema missing fields: {missing_fields}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Task 1: Detect Missing Values\n",
    "# ----------------------------\n",
    "\n",
    "def detect_missing_values(file_path):\n",
    "    \"\"\"\n",
    "    Load CSV and detect missing values with robust error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = load_csv_with_checks(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot proceed with missing values detection: {e}\")\n",
    "        return\n",
    "    \n",
    "    missing_counts = df.isnull().sum()\n",
    "    total_missing = missing_counts.sum()\n",
    "\n",
    "    if total_missing == 0:\n",
    "        print(\"No missing values detected in the dataset.\")\n",
    "    else:\n",
    "        print(f\"Total missing values in dataset: {total_missing}\")\n",
    "        print(\"Missing values per column:\")\n",
    "        print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# ----------------------------\n",
    "# Task 2: Validate Data Types in JSON\n",
    "# ----------------------------\n",
    "\n",
    "def validate_data_types(json_file, schema):\n",
    "    \"\"\"\n",
    "    Validate data types in JSON records against expected schema with error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = load_json_with_checks(json_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot proceed with data type validation: {e}\")\n",
    "        return\n",
    "    \n",
    "    if not isinstance(data, list):\n",
    "        print(\"Error: JSON root element should be a list of records.\")\n",
    "        return\n",
    "    \n",
    "    # Check schema completeness using first record as sample\n",
    "    validate_schema_completeness(schema, data[0])\n",
    "    \n",
    "    errors = []\n",
    "    for i, record in enumerate(data):\n",
    "        for field, expected_type in schema.items():\n",
    "            if field not in record:\n",
    "                errors.append(f\"Record {i}: Missing field '{field}'\")\n",
    "            else:\n",
    "                if not check_field_type(record[field], expected_type):\n",
    "                    errors.append(\n",
    "                        f\"Record {i}: Field '{field}' expected {expected_type.__name__}, \"\n",
    "                        f\"got {type(record[field]).__name__}\"\n",
    "                    )\n",
    "    \n",
    "    if errors:\n",
    "        print(\"Data type validation errors found:\")\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "    else:\n",
    "        print(\"All records match the expected schema.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Task 3: Remove Duplicate Records in CSV\n",
    "# ----------------------------\n",
    "\n",
    "def remove_duplicates(file_path):\n",
    "    \"\"\"\n",
    "    Find and remove duplicate records from CSV with error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = load_csv_with_checks(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot proceed with duplicate removal: {e}\")\n",
    "        return\n",
    "    \n",
    "    duplicates = df[df.duplicated()]\n",
    "    print(f\"Number of duplicate records found: {len(duplicates)}\")\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        print(\"Duplicate records:\")\n",
    "        print(duplicates)\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    print(f\"Number of records after removing duplicates: {len(df_cleaned)}\")\n",
    "    \n",
    "    cleaned_file_path = 'cleaned_' + os.path.basename(file_path)\n",
    "    df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"Cleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Example usage\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Task 1 example:\n",
    "    print(\"=== Detect Missing Values ===\")\n",
    "    detect_missing_values('your_data.csv')\n",
    "    \n",
    "    # Task 2 example:\n",
    "    print(\"\\n=== Validate Data Types ===\")\n",
    "    expected_schema = {\n",
    "        \"id\": int,\n",
    "        \"name\": str,\n",
    "        \"age\": int,\n",
    "        \"email\": str,\n",
    "        \"is_active\": bool,\n",
    "        \"balance\": float\n",
    "    }\n",
    "    validate_data_types('data.json', expected_schema)\n",
    "    \n",
    "    # Task 3 example:\n",
    "    print(\"\\n=== Remove Duplicates ===\")\n",
    "    remove_duplicates('your_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Validate Data Types during Extraction\n",
    "**Description**: You have a JSON file that should have specific data types for each field. Write a script to validate if the data types match the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Define expected schema\n",
    "2. Validate data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Remove Duplicate Records in Data\n",
    "**Description**: You have a dataset with duplicate entries. Write a Python script to find and remove duplicate records using Pandas.\n",
    "\n",
    "**Steps**:\n",
    "1. Find duplicate records\n",
    "2. Remove duplicates\n",
    "3. Report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
